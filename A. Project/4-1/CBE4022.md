ì¸ê³µì§€ëŠ¥:ë”¥ëŸ¬ë‹

# 0. Syllabus


ğŸ“— Book Recommended
- Main Book - A. Zhang, Z. C. Lipton, M. Li and A. J. Smola, "Dive into Deep Learning", Cambridge University Press (2024)
- Probability - 8. D. P. Bertsekas and J. N. Tsitsiklis, "Introduction to Probability", 2nd Ed., Athena Scientific (2008)
- Optimization - 9. D. G. Luenberger, "Linear and Nonlinear Programming", 2nd. Ed., Addison-Wesley (1984)

ë³¸ ê°•ì˜ì—ì„  ì½”ë”© ì‹¤ìŠµì€ ì§„í–‰í•˜ì§€ ì•Šê³  ì´ë¡  ìœ„ì£¼ë¡œ ìˆ˜ì—…ì´ ì§„í–‰ëœë‹¤.

**Classical Machine Learning**ì€ êµ¬ì¡°í™”ëœ ë°ì´í„°ì™€ ë¹„êµì  ë‹¨ìˆœí•œ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ë° ê°•ì ì´ ìˆì§€ë§Œ, ì´ë¯¸ì§€ ì¸ì‹ì´ë‚˜ ìì—°ì–´ ì²˜ë¦¬ ê°™ì€ ë³µì¡í•œ ì‹¤ìƒí™œ ë¬¸ì œì—ì„œëŠ” í•œê³„ë¥¼ ë“œëŸ¬ëƒˆë‹¤.
**Deep Learning**ì€ ì´ëŸ° í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë°œì „í•œ ê¸°ìˆ ë¡œ, ëŒ€ëŸ‰ì˜ ë°ì´í„°ì™€ ê°•ë ¥í•œ ì—°ì‚° ìì›ì„ í™œìš©í•´ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ë†’ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•œë‹¤.

ì´ˆê¸°ì—ëŠ” ì£¼ë¡œ CPUë¥¼ ì‚¬ìš©í•´ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí–ˆì§€ë§Œ, ê³„ì‚°ëŸ‰ì´ ë§ì•„ì§€ë©´ì„œ ë³‘ë ¬ ì—°ì‚°ì— ìµœì í™”ëœ GPUê°€ í™œìš©ë˜ê¸° ì‹œì‘í–ˆë‹¤. ê·¸ ì†ë„ëŠ” ë¬´ë ¤ 50ë°° ê°€ê¹Œì´ í–¥ìƒë˜ì—ˆë‹¤.

ê³¼ê±°ì—ëŠ” Raw Data(ì›ë³¸ ë°ì´í„°)ë¥¼ ì‚¬ëŒì´ ì§ì ‘ ì •ì œí•˜ê³  íŠ¹ì§•ì„ ì¶”ì¶œí•œ í›„, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ë°©ì‹ì´ì—ˆë‹¤. ì¦‰, ë°ì´í„°ì—ì„œ ì˜ë¯¸ ìˆëŠ” Feature(íŠ¹ì§•)ë¥¼ ì‚¬ëŒì´ ì •ì˜í•˜ê³  ê°€ê³µí•˜ëŠ” ê³¼ì •ì´ í•„ìš”í–ˆë‹¤. í•˜ì§€ë§Œ Deep Learningì—ì„œëŠ” **End-to-End Learning**ì´ ê°€ëŠ¥í•´ì§€ë©´ì„œ, ì›ë³¸ ë°ì´í„°ë¥¼ ìµœì†Œí•œì˜ ì „ì²˜ë¦¬ë§Œ ê±°ì¹œ í›„ ëª¨ë¸ì— ì…ë ¥í•˜ë©´, ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ìœ ì˜ë¯¸í•œ íŠ¹ì§•ì„ í•™ìŠµí•˜ë„ë¡ ë°”ë€Œì—ˆë‹¤.

ì¦‰, "Raw Data â†’ Feature Engineering â†’ Learning"ì—ì„œ  
"Raw Data â†’ Learning (ëª¨ë¸ì´ ì§ì ‘ íŠ¹ì§•ì„ í•™ìŠµ)"ìœ¼ë¡œ ë³€í™”í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.

ì´ë¥¼ í†µí•´ ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ë³µì¡í•œ íŒ¨í„´ì„ ë” íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìœ¼ë©°, íŠ¹íˆ ì´ë¯¸ì§€, ìŒì„±, ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

Transformer, Titansê³¼ ê°™ì€ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ë“¤ë„ ì°¨ì°¨ ë°°ìš¸ ì˜ˆì •ì´ë‹¤.

# 1. Linear Algebra

## 1.1 Eigenvalues and Eigendecomposition

eigen valueëŠ” square matrixì— ëŒ€í•´ì„œë§Œ ì •ì˜ëœë‹¤.
$\vec x ^{*}$: Transpose consugate $\vec x^{\top}$

Fact: If $v$ is an eigenvector associated with $\lambda$, so is $av$ with $a\neq 0$.
eigenvectorì—ì„œ ì¤‘ìš”í•œê±´ sizeê°€ ì•„ë‹ˆë¼ ë°©í–¥ì´ë‹¤.

Fact:
$A\vec x = \lambda \vec x$
$(A - \lambda I)\vec x = \vec 0$ì—ì„œ $(A - \lambda I)$ê°€ Invertibleí•˜ë©´
$\vec x = \vec 0$ ì¦‰, eigen vectorë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤.
ë”°ë¼ì„œ Non-Invertibleí•´ì•¼ í•˜ë¯€ë¡œ ì¡°ê±´ì— ë”°ë¼ $\det(A - \lambda I) = 0$ì´ì—¬ì•¼ í•œë‹¤.
$\mathcal{N}(A - \lambda I)$ ($\mathcal{N}$: Null Space)
ë”°ë¼ì„œ Eigen vectorëŠ” $\mathcal{N}$ì˜ Elementì´ë‹¤.

Null Spaceì˜ Demension ë§Œí¼ independantí•œ eigen valueë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë‹¤.
Demension 1ì´ë©´ ì ì´ë¯€ë¡œ í•˜ë‚˜ë§Œ ìˆê³ 
Demension 2ë©´ ë‘ ê°œ..
ë”°ë¼ì„œ $nullity(A - \lambda I)$ë§Œí¼ Independantí•œ eigen valueê°€ ìƒê¸°ëŠ” ê²ƒì´ë‹¤.

Theorem:
nullity nì¸ Matrixì—ì„œ nê°œì˜ ì„œë¡œ ë‹¤ë¥¸ eigen valueê°€ ë‚˜ì˜¤ë©´ ëª¨ë“  eigen vectorëŠ” linearly independentí•˜ë‹¤.

WLOG: Without Loss of Generality

`86p.`

`96p.`

# Midterm

ğŸ“Œ SVD ì‹œí—˜..?
ğŸ“Œ Gradient Descent Method
ğŸ“Œ ë² ì´ì¦ˆ ì •ë¦¬, ì¡°ê±´ë¶€í™•ë¥ ì„ ì´ìš©í•œ í™•ë¥  ë¬¸ì œ
ğŸ“Œ **8.3 Backpropagation ë¬´ì¡°ê±´ ì‹œí—˜ì— ë‚˜ì˜´**, `98-99p.` **ìœ ë„ê³¼ì • ë¬´ì¡°ê±´ ì‹œí—˜ì— ë‚˜ì˜´**
ğŸ“Œ Overfitting, Underfittingì€ ë¬´ì—‡ì¸ê°€
ğŸ“Œ PCA(principal component analysis)ëŠ” ë¬´ì—‡ì¸ê°€

- ì‹œí—˜ë²”ìœ„: `-99p.`
- Date: 5/13 15:00-16:15 DB101

`118p.`

# 11. Reinforcement Learning

#### Reinforcement Learning (ê°•í™” í•™ìŠµ)

ê°•í™” í•™ìŠµì€ 

ê°•í™” í•™ìŠµì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ ë„¤ ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:
- Agent
- Environment
- State
- Action
- Reward

í•µì‹¬ ê°œë…ì€ ë‹¤ìŒê³¼ ê°™ë‹¤:
- Reward Function
- State Dynamics
- Value Function
- Policy

#### Policy Iteration


## 11.1 Reinforcement Learning Problem

