#### condaë¥¼ í†µí•œ ê°€ìƒí™˜ê²½ ì„¤ì •
```powershell
(base) PS C:\Users\82104> conda create -n vision_module python=3.10
(base) PS C:\Users\82104> conda activate vision_module
(vision_module) PS C:\Users\82104> pip install mediapipe opencv-python numpy
(vision_module) PS C:\Users\82104> python -c "import mediapipe as mp; import cv2; print('âœ… ì„¤ì¹˜ ì™„ë£Œ')"
âœ… ì„¤ì¹˜ ì™„ë£Œ
```

#### `hello_mediapipe.py`
```python
import cv2
import mediapipe as mp

# Mediapipe ì„¤ì •
mp_hands = mp.solutions.hands # ì† ì¸ì‹ ëª¨ë¸ ìƒì„±ì„±
 # ìµœëŒ€ ì† 1ê°œ, ì†ì„ ìµì‹í•  ìµœì†Œ ì‹ ë¢°ë„, ì¶”ì  ìƒíƒœ ìœ ì§€ ìµœì†Œ ì‹ ë¢°ë„
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils # ì† ê´€ì ˆì— ì‹œê°ì ìœ¼ë¡œ ì„ ì„ ì—°ê²°í•´ì£¼ëŠ” Util


def get_finger_status(hand):
    """
    ì†ê°€ë½ì´ í´ì ¸ ìˆëŠ”ì§€ ì ‘í˜€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜

    Input:
        hand
    Returns:
        fingers_status[i, i, i, i, i](list)
        - 1: í´ì ¸ ìˆì„ ë•Œ
        - 0: ì ‘í˜€ ìˆì„ ë•Œ
    """
    # ì˜¤ë¥¸ì† ê¸°ì¤€
    fingers = []

    # ì—„ì§€ í¼ì³ì¡ŒëŠ”ì§€ ì—¬ë¶€:
    # ëœë“œë§ˆí¬ 4ê°€ ëœë“œë§ˆí¬ 2ì˜ ì˜¤ë¥¸ìª½ì— ìˆìœ¼ë©´ í¼ì³ì§„ ìƒíƒœ
    if hand.landmark[4].x < hand.landmark[3].x:
        fingers.append(1)
    else:
        fingers.append(0)

    # ë‚˜ë¨¸ì§€ ì†ê°€ë½ í¼ì³ì¡ŒëŠ”ì§€ ì—¬ë¶€:
    # ê° ì†ê°€ë½ì˜ íŒ (8, 12, 16, 20)ì´ PIP (6, 10, 14, 18) ìœ„ì— ìˆìœ¼ë©´ í¼ì³ì§„ ìƒíƒœ
    tips = [8, 12, 16, 20]
    pip_joints = [6, 10, 14, 18]
    for tip, pip in zip(tips, pip_joints):
        if hand.landmark[tip].y < hand.landmark[pip].y:
            fingers.append(1)
        else:
            fingers.append(0)

    return fingers


def recognize_gesture(fingers_status):
    '''
    ì–´ëŠ ì†ê°€ë½ì´ í¼ì³ì¡ŒëŠ”ì§€ì— ë”°ë¼ ì œìŠ¤ì³ì˜ ì˜ë¯¸ë¥¼ ì •ì˜í•¨

    Input: 
        fingers_status(list)
    Returns:
        status(string)
    '''
    if fingers_status == [0, 0, 0, 0, 0]:
        return 'fist'
    elif fingers_status == [0, 1, 0, 0, 0]:
        return 'point'
    elif fingers_status == [1, 1, 1, 1, 1]:
        return 'open'
    elif fingers_status == [0, 1, 1, 0, 0]:
        return 'peace'
    elif fingers_status == [1, 1, 0, 0, 0]:
        return 'standby'


# ì›¹ìº  ì„¤ì •
video = cv2.VideoCapture(0)

print("Webcam is running... Press 'ESC' to exit.")
while video.isOpened():
    ret, frame = video.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(img_rgb)

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            fingers_status = get_finger_status(hand_landmarks)
            print(recognize_gesture(fingers_status))

            # ì† ëœë“œë§ˆí¬ì™€ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    cv2.imshow('Hand Gesture', frame)
    if cv2.waitKey(1) == 27:  # ESC í‚¤ë¡œ ì¢…ë£Œ
        break

video.release()
cv2.destroyAllWindows()
```

#### ì‹¤í–‰, VS Code

- `ctrl + shift + p` > Python:ì¸í„°í”„ë¦¬í„° ì„ íƒ > `Python 3.10.16(visual_module)` ì„ íƒ
- ì½˜ì†” ì°½ì—ì„œ `conda activate visual_module`
- `python hello_mediapipe.py` ë˜ëŠ” `F5`í‚¤ë¡œ ì‹¤í–‰

**ì‹¤í–‰í™”ë©´** `í™”ë©´ ìŠ¤í‹°ì»¤ë¡œ ê°€ë ¤ë†“ìŒ`
![](../../Z.%20Docs/img/Pasted%20image%2020250328174656.png)

---
#### Current Hand Poses

ğŸ‘Œ
âœŠ
â˜ï¸
âœ‹
âœŒï¸
ğŸ‘†
ğŸ‘
ğŸ¤™
ğŸ¤Ÿ

---